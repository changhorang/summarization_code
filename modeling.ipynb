{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modeling.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1NEjzM9c75lwWga1V4J4wNK3upGjrfYKm","authorship_tag":"ABX9TyMC2p8LAbalBh8CIFWYyDH9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-0ejaEMPC0vo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649696453601,"user_tz":-540,"elapsed":19359,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"36adc2eb-c703-4c40-aa22-60bb81692e5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 4.7 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 27.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 21.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 32.4 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.18.0\n"]}],"source":["!pip install transformers\n","# !pip install rouge\n","# !pip install datasets\n","# !pip install sentencepiece\n","# !pip install rouge_score\n","# !pip install wandb"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-ut952qbxyH","executionInfo":{"status":"ok","timestamp":1649696474029,"user_tz":-540,"elapsed":20438,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"515bd517-83c5-4cc4-8fdf-2b06e395db70"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"YJqHvB3A_rfJ","executionInfo":{"status":"ok","timestamp":1649696474029,"user_tz":-540,"elapsed":5,"user":{"displayName":"김창호","userId":"09806159714715776157"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir(r'/content/drive/MyDrive/대학원_개인/KCC 관련 자료/KCC summarization 구현')\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YHvgsJ9-xuxq","executionInfo":{"status":"ok","timestamp":1649696474029,"user_tz":-540,"elapsed":4,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"9aa263bb-32ce-4895-dffe-4845402ac068"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/대학원_개인/KCC 관련 자료/KCC summarization 구현'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!python main.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jp7sXC1mkd5a","outputId":"45100f45-0080-4b4d-db0a-697c7aac3929"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: 100% 208k/208k [00:00<00:00, 1.87MB/s]\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 24.8kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 539kB/s]\n","Tokenizing...\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Downloading: 100% 532M/532M [00:13<00:00, 42.5MB/s]\n","Downloading: 100% 416M/416M [00:20<00:00, 21.5MB/s]\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   1    |   100   |   0.517983   |     -      |     -    \n","   1    |   200   |   0.475222   |     -      |     -    \n","   1    |   300   |   0.468795   |     -      |     -    \n","   1    |   400   |   0.465617   |     -      |     -    \n","   1    |   500   |   0.461365   |     -      |     -    \n","   1    |   514   |   0.556228   |     -      |     -    \n"]}]},{"cell_type":"code","source":["!python main.py --epochs 4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ji93b6t2gJEi","executionInfo":{"status":"ok","timestamp":1649668582915,"user_tz":-540,"elapsed":6804305,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"b34501bb-5135-446c-a3fa-403ef9bd6b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: 100% 878k/878k [00:00<00:00, 6.57MB/s]\n","Downloading: 100% 446k/446k [00:00<00:00, 3.39MB/s]\n","Downloading: 100% 1.68k/1.68k [00:00<00:00, 1.87MB/s]\n","Downloading: 100% 208k/208k [00:00<00:00, 1.79MB/s]\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 40.0kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 656kB/s]\n","Tokenizing...\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Downloading: 100% 532M/532M [00:12<00:00, 43.3MB/s]\n","Downloading: 100% 416M/416M [00:12<00:00, 35.3MB/s]\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   1    |   100   |   0.528794   |     -      |     -    \n","   1    |   200   |   0.481055   |     -      |     -    \n","   1    |   300   |   0.471873   |     -      |     -    \n","   1    |   400   |   0.468286   |     -      |     -    \n","   1    |   500   |   0.464921   |     -      |     -    \n","   1    |   514   |   0.560990   |     -      |     -    \n","   1    |    -    |   0.485195   |  0.602517  |   67.66  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   2    |   100   |   0.461923   |     -      |     -    \n","   2    |   200   |   0.460649   |     -      |     -    \n","   2    |   300   |   0.459991   |     -      |     -    \n","   2    |   400   |   0.461098   |     -      |     -    \n","   2    |   500   |   0.458923   |     -      |     -    \n","   2    |   514   |   0.552554   |     -      |     -    \n","   2    |    -    |   0.463022   |  0.913498  |   67.66  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   3    |   100   |   0.457447   |     -      |     -    \n","   3    |   200   |   0.458919   |     -      |     -    \n","   3    |   300   |   0.458564   |     -      |     -    \n","   3    |   400   |   0.458947   |     -      |     -    \n","   3    |   500   |   0.458089   |     -      |     -    \n","   3    |   514   |   0.550807   |     -      |     -    \n","   3    |    -    |   0.460904   |  0.784432  |   67.66  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   4    |   100   |   0.456649   |     -      |     -    \n","   4    |   200   |   0.457324   |     -      |     -    \n","   4    |   300   |   0.457490   |     -      |     -    \n","   4    |   400   |   0.455855   |     -      |     -    \n","   4    |   500   |   0.457085   |     -      |     -    \n","   4    |   514   |   0.553568   |     -      |     -    \n","   4    |    -    |   0.459509   |  0.960540  |   67.66  \n","----------------------------------------------------------------------\n","\n","\n","Training complete!\n"]}]},{"cell_type":"code","source":["!python main.py --epochs 6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgE1Sg62h-31","outputId":"43a686e4-c8b1-443e-997a-21bae4b9a4e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing...\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   1    |   100   |   0.519237   |     -      |     -    \n","   1    |   200   |   0.479455   |     -      |     -    \n"]}]},{"cell_type":"code","source":["!unzip '/content/drive/MyDrive/대학원_개인/코딩구현/BART_summarization/data/archive.zip'"],"metadata":{"id":"VAovyASR7kUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip '/content/drive/MyDrive/대학원_개인/코딩구현/BART_summarization/data/archive_bbc.zip'"],"metadata":{"id":"owDzi_qCCPLB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","all_data = []\n","Articles = []\n","Summaries = []\n","for d, path,filenames in (os.walk('/content/bbc news summary/BBC News Summary')):\n","    for file in filenames:\n","        if os.path.isfile(d+'/'+file):\n","            if('Summaries' in d+'/'+file):\n","                with open(d+'/'+file,'r',errors='ignore') as f:\n","                    summary=''.join([i.rstrip() for i in f.readlines()])\n","                    Summaries.append(summary)\n","                    f.close()\n","            else:\n","                with open(d+'/'+file,'r',errors='ignore') as f:\n","                    Article=''.join([i.rstrip() for i in f.readlines()])\n","                    Articles.append(' '.join([w for w in Article.split()]))\n","                    f.close()"],"metadata":{"id":"qEHfyabKKep6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# /content/bbc news summary/BBC News Summary/News Articles/politics\n","# train_data = pd.read_csv('./cnn_dailymail/train.csv').drop('id', axis=1)\n","# train_data['label'] = 1\n","# train_input = train_data['article']\n","# train_summary = train_data['highlights']\n","\n","# validation_data = pd.read_csv('./cnn_dailymail/validation.csv').drop('id', axis=1)\n","# validation_data['label'] = 1\n","# validation_input = validation_data['article']\n","# validation_summary = validation_data['highlights']\n","# validation_label = validation_data['label']\n","\n","_data = pd.read_csv('./cnn_dailymail/test.csv').drop('id', axis=1)\n","_data['label'] = 1\n","_input = _data['article']\n","_summary = _data['highlights']\n","_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQrfoIoLC3sg","executionInfo":{"status":"ok","timestamp":1649612596552,"user_tz":-540,"elapsed":1046,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"4c9c1c9f-83ca-4a50-d8c1-7987b76aa387"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11490, 3)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["data_ = pd.DataFrame({'article':Articles, 'highlights':Summaries})\n","data_['label'] = 0\n","data_.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Jhqk0T8xPvvo","executionInfo":{"status":"ok","timestamp":1649612614893,"user_tz":-540,"elapsed":418,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"2973da9d-1abc-434c-a295-cb3a73d298c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             article  \\\n","0  Howard denies split over ID cardsMichael Howar...   \n","1  Mrs Howard gets key election roleMichael Howar...   \n","2  Mayor will not retract Nazi jibeLondon mayor K...   \n","3  Cabinet anger at Brown cash raidMinisters are ...   \n","4  Police urge pub closure powerNew powers are ne...   \n","\n","                                          highlights  label  \n","0  Michael Howard has denied his shadow cabinet w...      0  \n","1  Mr Howard will host a news conference at the p...      0  \n","2  London mayor Ken Livingstone has again refused...      0  \n","3  But he said local governments had to deliver g...      0  \n","4  The new licensing laws will give police greate...      0  "],"text/html":["\n","  <div id=\"df-dddf62c9-d966-4c5e-9f32-3c46c7866099\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article</th>\n","      <th>highlights</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Howard denies split over ID cardsMichael Howar...</td>\n","      <td>Michael Howard has denied his shadow cabinet w...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Mrs Howard gets key election roleMichael Howar...</td>\n","      <td>Mr Howard will host a news conference at the p...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mayor will not retract Nazi jibeLondon mayor K...</td>\n","      <td>London mayor Ken Livingstone has again refused...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cabinet anger at Brown cash raidMinisters are ...</td>\n","      <td>But he said local governments had to deliver g...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Police urge pub closure powerNew powers are ne...</td>\n","      <td>The new licensing laws will give police greate...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dddf62c9-d966-4c5e-9f32-3c46c7866099')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dddf62c9-d966-4c5e-9f32-3c46c7866099 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dddf62c9-d966-4c5e-9f32-3c46c7866099');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# train_data = pd.concat([data_[:int(data_.shape(0)*0.6)], _data[:int(data_.shape(0)*0.6)]], ignore_index=True)\n","\n","# csv 파일로 저장\n","train_data = pd.concat([data_[:int(data_.shape[0]*0.6)], _data[:int(_data.shape[0]*0.6)]], ignore_index=True)\n","valid_data = pd.concat([data_[int(data_.shape[0]*0.6):], _data[int(_data.shape[0]*0.6):]], ignore_index=True)\n","test_data = valid_data[int(valid_data.shape[0]*0.5):]\n","valid_data = valid_data[:int(valid_data.shape[0]*0.5)]\n","\n","train_data.to_csv('data/train_data.csv', sep='\\t', index=False)\n","valid_data.to_csv('data/valid_data.csv', sep='\\t', index=False)\n","test_data.to_csv('data/test_data.csv', sep='\\t', index=False)"],"metadata":{"id":"1V6H2lbUUdJI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","train_data = pd.read_csv('data/train_data.csv', sep='\\t')"],"metadata":{"id":"pyNLqn7XtemH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.tail()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"hsrwrHg3tsSL","executionInfo":{"status":"ok","timestamp":1649614979981,"user_tz":-540,"elapsed":394,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"e5fa43f4-9a7e-4e14-8ffb-7a0123643091"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                article  \\\n","8224  An unemployed alcoholic who boasts of fatherin...   \n","8225  Fulham will sound out Brentford manager Mark W...   \n","8226  Shia paramilitary fighters looting and setting...   \n","8227  The Tories are set to steal Labour’s thunder b...   \n","8228  Ethan Czahor (pictured) has launched ‘Clear’ w...   \n","\n","                                             highlights  label  \n","8224  Mike Holpin, from Ebbw Vale in Monmouthshire, ...      1  \n","8225  Fulham are planning to swoop for Brentford bos...      1  \n","8226  Ahmed al-Karim said fighters had burnt 'hundre...      1  \n","8227  Osborne accidentally divulged plans for a ‘tax...      1  \n","8228  App created to remove posts that might cause p...      1  "],"text/html":["\n","  <div id=\"df-a10059f0-6dd4-4146-9607-ef4f889ac8a6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article</th>\n","      <th>highlights</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8224</th>\n","      <td>An unemployed alcoholic who boasts of fatherin...</td>\n","      <td>Mike Holpin, from Ebbw Vale in Monmouthshire, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8225</th>\n","      <td>Fulham will sound out Brentford manager Mark W...</td>\n","      <td>Fulham are planning to swoop for Brentford bos...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8226</th>\n","      <td>Shia paramilitary fighters looting and setting...</td>\n","      <td>Ahmed al-Karim said fighters had burnt 'hundre...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8227</th>\n","      <td>The Tories are set to steal Labour’s thunder b...</td>\n","      <td>Osborne accidentally divulged plans for a ‘tax...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8228</th>\n","      <td>Ethan Czahor (pictured) has launched ‘Clear’ w...</td>\n","      <td>App created to remove posts that might cause p...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a10059f0-6dd4-4146-9607-ef4f889ac8a6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a10059f0-6dd4-4146-9607-ef4f889ac8a6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a10059f0-6dd4-4146-9607-ef4f889ac8a6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["train_data.shape, valid_data.shape, test_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsYnIOWWmNfk","executionInfo":{"status":"ok","timestamp":1649613895194,"user_tz":-540,"elapsed":441,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"e51e098c-1c32-4c5a-9d84-8a96edccf98a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((8229, 3), (2743, 3), (2743, 3))"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["!python main.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLhjZ1IBcFJi","executionInfo":{"status":"ok","timestamp":1649642207301,"user_tz":-540,"elapsed":2638390,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"b4da4d67-b5ae-4d3c-9cd7-0a3b8256190d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: 100% 878k/878k [00:00<00:00, 1.85MB/s]\n","Downloading: 100% 446k/446k [00:00<00:00, 1.11MB/s]\n","Downloading: 100% 1.68k/1.68k [00:00<00:00, 1.04MB/s]\n","Downloading: 100% 208k/208k [00:00<00:00, 655kB/s]\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 30.1kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 609kB/s]\n","Tokenizing...\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Downloading: 100% 532M/532M [00:12<00:00, 44.8MB/s]\n","Downloading: 100% 416M/416M [00:21<00:00, 20.7MB/s]\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   1    |   100   |   0.513499   |     -      |     -    \n","   1    |   200   |   0.474238   |     -      |     -    \n","   1    |   300   |   0.471029   |     -      |     -    \n","   1    |   400   |   0.466519   |     -      |     -    \n","   1    |   500   |   0.462395   |     -      |     -    \n","   1    |   514   |   0.554269   |     -      |     -    \n","   1    |    -    |   0.479692   |  0.535135  |   67.66  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc \n","----------------------------------------------------------------------\n","   2    |   100   |   0.462723   |     -      |     -    \n","   2    |   200   |   0.459646   |     -      |     -    \n","   2    |   300   |   0.460099   |     -      |     -    \n","   2    |   400   |   0.461316   |     -      |     -    \n","   2    |   500   |   0.458148   |     -      |     -    \n","   2    |   514   |   0.543188   |     -      |     -    \n","   2    |    -    |   0.462642   |  0.564850  |   67.66  \n","----------------------------------------------------------------------\n","\n","\n","Training complete!\n"]}]},{"cell_type":"code","source":["from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig\n","\n","model = Bart_summarization()\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"],"metadata":{"id":"i29HduvgK_4k","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1649096456422,"user_tz":-540,"elapsed":10477,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"b412e1ff-bd62-4266-c7ac-dbdc2eafd92d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a05555ec902b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBartForConditionalGeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBartTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBartConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBart_summarization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBartTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/bart-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Bart_summarization' is not defined"]}]},{"cell_type":"code","source":["# model2 = model.get_encoder()\n","# model.lm_head.out_features, model2.embed_tokens.embedding_dim"],"metadata":{"id":"UBpT_n68Nzzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LONG_BORING_TENNIS_ARTICLE = \"\"\"\n"," Andy Murray  came close to giving himself some extra preparation time for his w\n","edding next week before ensuring that he still has unfinished tennis business to\n"," attend to. The world No 4 is into the semi-finals of the Miami Open, but not be\n","fore getting a scare from 21 year-old Austrian Dominic Thiem, who pushed him to \n","4-4 in the second set before going down 3-6 6-4, 6-1 in an hour and three quarte\n","rs. Murray was awaiting the winner from the last eight match between Tomas Berdy\n","ch and Argentina's Juan Monaco. Prior to this tournament Thiem lost in the secon\n","d round of a Challenger event to soon-to-be new Brit Aljaz Bedene. Andy Murray p\n","umps his first after defeating Dominic Thiem to reach the Miami Open semi finals\n"," . Muray throws his sweatband into the crowd after completing a 3-6, 6-4, 6-1 vi\n","ctory in Florida . Murray shakes hands with Thiem who he described as a 'strong \n","guy' after the game . And Murray has a fairly simple message for any of his fell\n","ow British tennis players who might be agitated about his imminent arrival into \n","the home ranks: don't complain. Instead the British No 1 believes his colleagues\n"," should use the assimilation of the world number 83, originally from Slovenia, a\n","s motivation to better themselves. At present any grumbles are happening in priv\n","ate, and Bedene's present ineligibility for the Davis Cup team has made it less \n","of an issue, although that could change if his appeal to play is allowed by the \n","International Tennis Federation. Murray thinks anyone questioning the move, now \n","it has become official, would be better working on getting their ranking closer \n","to his. 'If he was 500 in the world they wouldn't be that fussed about it but ob\n","viously he threatens their position a bit,' said the 27 year-old Scot. ' and he'\n","s obviously the British number two, comfortably. 'So they can complain but the b\n","est thing to do is use it in the right way and accept it for what it is, and try\n"," to use it as motivation whether they agree with it or not. He's British now so \n","they've just got to deal with it. Murray stretches for a return after starting h\n","is quarter final match slowly on the show court . Thiem held nothing back as he \n","raced through the opening set, winning it 6-3 with a single break . The young Au\n","strian is considered to be one of the hottest prospects on the ATP Tour . 'I wou\n","ld hope that all the guys who are below him now like James (Ward) , Kyle (Edmund\n",") , Liam (Broady) they will use it as motivation. If he becomes eligible for Dav\n","is Cup then those guys are going to have to prove themselves. 'It can only be se\n","en as a positive for those guys using it to try to get better. He's a good playe\n","r but so are James and Kyle and Liam has improved. Aljaz is there, he's on the t\n","our every week, the other guys aren't quite there yet.' For the first time Murra\n","y, who has an encyclopaedic knowledge of the top 100, gave his opinion of Bedene\n",": 'He's a good player with a very good serve. He's a legitimate top 100 player, \n","when he plays Challengers he's there or thereabouts, when he plays on the main t\n","our he wins matches, it's not like he turns up and always loses in the first rou\n","nd. Murray's fiancee was once again watching from the stands shaded by a huge br\n","immed hat . Kim Sears flashes her enormous diamond engagement ring while watchin\n","g her beau on court . 'He had a bad injury last year (wrist) but has recovered w\n","ell. I would imagine he would keep moving up the rankings although I don't know \n","exactly how high he can go. I've practised with him a couple of times, I haven't\n"," seen him play loads, but when you serve as well as he does it helps. I would im\n","agine he' s going to be comfortably in the top 70 or 80 in the world for a while\n",".' It is understood the Lawn Tennis Association will give background support to \n","his case regarding the Davis Cup but have made it clear that the onus is on him \n","to lead the way. An official statement said: 'To have another player in the men'\n","s top 100 is clearly a positive thing for British tennis and so we very much wel\n","come Aljaz's change in citizenship.' The last comparable switch came twenty year\n","s ago when Greg Rusedski arrived from Canada. It was by no means universally pop\n","ular but, like Bedene, he pledged that he was in for the long haul and, in fairn\n","ess to him, he proved true to his word. Loising the first set shocked Murray int\n","o life as he raced to a commanding lead in the second . The No 3 seed sent over \n","a few glaring looks towards his team before winning the second set . Murray had \n","to put such matters aside as he tackled the unusually talented Thiem, a delight \n","to watch. Coached by Boris Becker's veteran mentor Gunter Bresnik, he slightly r\n","esembles Andy Roddick and hits with similar power but more elegance. His single \n","handed backhand is a thing of rare beauty. However, he has had a mediocre season\n"," coming into this event and there was little to forewarn of his glorious shotmak\n","ing that seemed to catch Murray unawares early on. The world No 4 looked to have\n"," worked him out in the second, but then suffered one of his periopdic mental lap\n","ses and let him back in from 4-1 before closing it out with a break. After break\n","ing him for 3-1 in the decider the Austrian whirlwind burnt itself out. 'He's a \n","strong guy who hits the ball hard and it became a very physical match,' said Mur\n","ray. Murray was presented with a celebratory cake after winning his 500th match \n","in the previous round .\n","\"\"\".replace('\\n','')\n","\n","labels = ' Andy Murray  came close to giving himself some extra preparation time for his wedding next week'"],"metadata":{"id":"yFhC0oPUfLVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article_label = tokenizer.batch_encode_plus([labels], return_tensors='pt', max_length=1024)\n","label = article_label['input_ids']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UHaurbfIo-ye","executionInfo":{"status":"ok","timestamp":1649302129915,"user_tz":-540,"elapsed":231,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"4135606b-e4cc-4047-bfab-b5e937fae74b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"code","source":["model = Bart_summarization()"],"metadata":{"id":"JMzoB4iE0DYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article_input_ids = tokenizer.batch_encode_plus([LONG_BORING_TENNIS_ARTICLE], return_tensors='pt', max_length=1024)\n","article_input_ids\n","input_ids = article_input_ids['input_ids']\n","attention_mask = article_input_ids['attention_mask']\n","summary_ids = model(input_ids, attention_mask, label)\n","\n","# # summary_ids\n"],"metadata":{"id":"YRBjRobCelZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary_ids.keys()#['lm_logits']\n","# masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n","# masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzwWVKb6hsHA","executionInfo":{"status":"ok","timestamp":1649099492163,"user_tz":-540,"elapsed":2,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"0af22c2c-0f70-44f2-ac70-7e2e64d7632a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['loss', 'logits', 'encoder_last_hidden_state'])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["summary_idss = model.generate(input_ids)"],"metadata":{"id":"RReSGfZI09eZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary_idss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCDI3avt1Q4U","executionInfo":{"status":"ok","timestamp":1649302173801,"user_tz":-540,"elapsed":269,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"cba05956-95f6-4205-928b-70d62e74c5d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   2,    0, 5095, 4479, 1437,  376,  593,    7, 1311, 1003,  103, 1823,\n","         7094,   86,   13,   39, 3312,  220,  186,    2]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["article_input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48BNZIuH0anx","executionInfo":{"status":"ok","timestamp":1649099509081,"user_tz":-540,"elapsed":267,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"b61149b9-126d-4691-bb45-8db5002081a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    0,  5095,  4479,  ..., 11989,  6409,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["summary_ids['loss']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ksDC2JDKpk0E","executionInfo":{"status":"ok","timestamp":1649093820449,"user_tz":-540,"elapsed":387,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"e470b39a-6d24-45b9-a5f2-1c49778f8d54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.2181, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["#  article_input_ids['attention_mask'].shape"],"metadata":{"id":"xCVRhdLv59pB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary_txt = []\n","summary_txt.append(tokenizer.batch_decode(summary_idss.squeeze(), skip_special_tokens=True))\n","summary_txt"],"metadata":{"id":"wZKm4Q_piPie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649302212991,"user_tz":-540,"elapsed":3,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"22f647e1-c41f-4c9a-c5ae-4f32ccaa59e8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['</s>',\n","  '<s>',\n","  ' Andy',\n","  ' Murray',\n","  ' ',\n","  ' came',\n","  ' close',\n","  ' to',\n","  ' giving',\n","  ' himself',\n","  ' some',\n","  ' extra',\n","  ' preparation',\n","  ' time',\n","  ' for',\n","  ' his',\n","  ' wedding',\n","  ' next',\n","  ' week',\n","  '</s>']]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig, BertModel\n","\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","\n","class Bart_summarization(nn.Module):\n","    def __init__(self):\n","        super(Bart_summarization, self).__init__()\n","        \n","        self.tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","        self.model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","        # self.model_config = BartConfig.from_pretrained('facebook/bart-base')\n","        \n","        # self.encoder = self.model.get_encoder()\n","        # self.decoder = self.model.get_decoder()\n","\n","        # bias\n","        # self.hidden_dim = self.encoder.embed_tokens.embedding_dim\n","        # self.vocab_size = self.model.lm_head.out_features\n","\n","    def forward(self, input_ids, attetion_mask, labels, token_type_ids=None):\n","\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels) # input_ids 만들기 (attention mask?)\n","        \n","        # summary_txt\n","        # summary_ids = self.model.generate(input_ids, attention_mask) \n","        # summary_txt = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","        return outputs#, summary_txt\n","\n","    def generate(self, b_input_ids, max_length=1024):\n","        return self.model.generate(b_input_ids)\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self, freeze_bert=False):\n","        super(BERTClassifier, self).__init__()\n","        D_in, H, D_out = 768, 50, 2 # bert hidden_dim=768\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","\n","        self.classifier = nn.Sequential(nn.Linear(D_in, H), nn.ReLU(), nn.Linear(H, D_out))\n","\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask) # (batch_size, sequence_length, hidden_size)\n","\n","        last_hidden_state_cls = outputs[0][:, 0, :] # 'latent_hidden_state' (batch_size, hidden_size) CLS token 추출\n","\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"],"metadata":{"id":"LOkfC8tq18wK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","import torch\n","\n","def loss_w(X):\n","    return -math.log(torch.sigmoid(X))\n","\n","def loss_u(s, t, C, X):\n","    density = 0.1 # hyper-parameter\n","    beta = 1 - t*0.05\n","    u_ = density*beta*(1 - C)*(loss_s(s, X))\n","    return u_\n","\n","def loss_s(s, t, c, X):\n","    loss_ = 0\n","    n = s - 1\n","\n","    for j in n:\n","        loss_ += loss_w(X)\n","    loss = loss_/n + loss_u(s, t, c, X)\n","    return loss"],"metadata":{"id":"PRJUq4NF0YIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# train_data = pd.read_csv('./cnn_dailymail/train.csv').drop('id', axis=1)\n","# train_input = train_data['article']\n","# train_summary = train_data['highlights']\n","\n","# validation_data = pd.read_csv('./cnn_dailymail/validation.csv').drop('id', axis=1)\n","# validation_input = validation_data['article']\n","# validation_summary = validation_data['highlights']\n","\n","test_data = pd.read_csv('./cnn_dailymail/test.csv').drop('id', axis=1)\n","test_input = test_data['article']\n","test_summary = test_data['highlights']\n","\n","# train_data.shape, validation_data.shape, test_data.shape"],"metadata":{"id":"P22iFbaJ9lYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample = test_input[:5].tolist()\n","for t in sample:\n","    input_ids = []\n","    attention_mask = []\n","    encoded_sent = tokenizer.encode_plus(t, max_length=1024, pad_to_max_length=True)\n","    \n","    input_ids.append(encoded_sent.get('input_ids'))\n","    attention_mask.append(encoded_sent.get('attention_mask'))\n","\n","input_ids = torch.tensor(input_ids)\n","attention_masks = torch.tensor(attention_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBFNlTuxR7Vu","executionInfo":{"status":"ok","timestamp":1648991700050,"user_tz":-540,"elapsed":2,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"5d6b0eae-880e-44ad-e81c-e6a135e4ac46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["import random\n","import torch\n","# from torch.utils.data.dataset import Dataset\n","\n","# class CustomDataset(Dataset):\n","#     def __init__(self, input_ids_list: list, label_list: list,\n","#                  attention_mask_list: list, token_type_ids_list: list = None, \n","#                  min_len: int = 4, max_len: int = 512):\n","#         data = []\n","#         for i, a, l in zip(input_ids_list, attention_mask_list, label_list):\n","#             if min_len <= len(i) <= max_len:\n","#                 data.append((i, a, l))\n","\n","#         self.data = tuple(data)\n","#         self.num_data = len(self.data)\n","\n","#     def __getitem__(self, index):\n","#         id_, attention_, label_ = self.data[index]\n","#         return id_, attention_, label_\n","    \n","#     def __len__(self):\n","#         return self.num_data"],"metadata":{"id":"j7qR5iUb2Edi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","def preprocessing_for_bart(data, tokenizer):\n","    data = np.array(data.tolist())\n","    # Create empty lists to store outputs\n","    input_ids = []\n","    attention_mask = []\n","    MAX_LEN = 1024\n","\n","    # For every sentence\n","    for sent in data:\n","        encoded_sent = tokenizer.encode_plus(text=sent,\n","                                            max_length=MAX_LEN,\n","                                            pad_to_max_length=True)\n","\n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_mask.append(encoded_sent.get('attention_mask'))\n","\n","    # Convert lists to tensors\n","    input_ids = torch.tensor(input_ids)\n","    attention_mask = torch.tensor(attention_mask)\n","    \n","    return input_ids, attention_mask\n","\n","\n","# test_input_ids.shape"],"metadata":{"id":"VSuUtzdHJY86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","print('Tokenizing...')\n","# train_input_ids, train_attention_mask = preprocessing_for_bart(train_input, tokenizer)\n","# validation_input_ids, validation_attention_mask = preprocessing_for_bart(validation_input, tokenizer)\n","test_input_ids, test_attention_mask = preprocessing_for_bart(test_input, tokenizer)\n","\n","# train_data = TensorDataset(train_input_ids, train_attention_mask)\n","# train_sampler = RandomSampler(train_data)\n","# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=16)\n","\n","# val_data = TensorDataset(validation_input_ids, validation_attention_mask)\n","# val_sampler = SequentialSampler(val_data)\n","# val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=16)\n","\n","test_data = TensorDataset(test_input_ids, test_attention_mask)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=8)"],"metadata":{"id":"66qq6gsY2ERG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648991797403,"user_tz":-540,"elapsed":97106,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"9b0ca14b-4a43-4236-f964-0fd955b0bd06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Bart_summarization().to(device)\n","\n","summary = []\n","for batch in test_dataloader:\n","    \n","    b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)\n","    \n","    with torch.no_grad():\n","        output = model(b_input_ids, b_attn_mask)\n","        summary.append(output)"],"metadata":{"id":"IBbiKoyn2EJ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b_input_ids.shape, b_attn_mask.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yP8rRAX_gbcI","executionInfo":{"status":"ok","timestamp":1648995390089,"user_tz":-540,"elapsed":235,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"55e120cc-6dbf-48a8-a66d-4bc00092c889"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2, 1024]), torch.Size([2, 1024]))"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# model = BartForConditionalGeneration.from_pretrained('facebook/bart-base').to(device)\n","model = Bart_summarization().to(device)\n","summary_ids = model.generate(b_input_ids, max_length=80)\n","summary = ([tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids])"],"metadata":{"id":"pBpJxiQEgbY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1BNqwHugbWy","executionInfo":{"status":"ok","timestamp":1648997376257,"user_tz":-540,"elapsed":247,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"148af39b-d7d4-4490-fa0e-71afde49f8e0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Brook Lopez dominated twin brother Robin with 32 points and nine rebounds as the Brooklyn Nets beat a weakened Portland Trail Blazers on Monday in the only game on the NBA schedule. The Trail Blazers left LaMarcus Aldridge and others home for the game that was postponed by bad weather on January 26 and couldn't stop Brook Lopez, who shot 15 for 25 from the field. Deron Williams added 24\",\n"," 'A Chinese hospital is being painstakingly moved just eight metres a day on 1,000 metal rollers  to prevent it from being demolished to make way for a new road. The building, which was built in the 1960s and belongs to Zheng Gong Hospital in Henan Province, was under threat of demolition as it is situated in the path of a road expansion project, reports\\xa0People']"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["test_summary.iloc[-2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"8mDC1FSzgbUC","executionInfo":{"status":"ok","timestamp":1648995656429,"user_tz":-540,"elapsed":271,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"6e5659fb-3c8f-4872-bc51-3482e739a8aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Brooklyn Nets beat the Portland Trail Blazers 106-96 in New York .\\nBrook Lopez scored 32 points for the Nets as they moved into seventh .\\nTrail Blazers were without LaMarcus Aldridge and a number of others .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["test_summary.iloc[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"50SgIJo-gaoQ","executionInfo":{"status":"ok","timestamp":1648995684727,"user_tz":-540,"elapsed":248,"user":{"displayName":"김창호","userId":"09806159714715776157"}},"outputId":"76fed313-f66d-49a5-ac94-b391bee38876"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Chinese hospital marked for demolition because of road expansion project .\\nBosses asked team of engineers to put two-storey building on 'wheels'\\nMore than 1,000 rollers have been placed under the large brick building .\\nIt is pushed 8 metres a day on giant metal rollers out of the demolition zone .\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":[""],"metadata":{"id":"ggpcLc_hgalQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"yAlOlWZNgah9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"kd6GERZDgacx"},"execution_count":null,"outputs":[]}]}